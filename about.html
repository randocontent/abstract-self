<html>

<head>
	<meta charset="UTF-8" />
	<title>ABSTRACT YOU</title>
	<meta http-equiv="X-UA-Compatible" content="IE=edge" />
	<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no" />
	<link rel="stylesheet" href="app/style.css" />
</head>

<body>
	<main class="about container">
		<div id="about-page" class="fullscreen">
			<div class="nav-header">
				<section>Abstract You</section>
				<section><a href="/">Back X</a></section>
			</div>

			<article>

				<div class="abstract">
					<section>
						<h1>Abstract You</h1>
						<p>
							But there is an inherent difficulty in the process of transforming
							someone into digital form. The technologies in use today are
							incapable of creating authentic and realistic digital twins.
							The assumption that human behavioural nuances and complex identity
							features (some of which are still elusive to us) can be sampled
							through analytical measures is misleading, and virtual entities
							created today might look like a specific person, but don’t ‘feel’
							like that person. This dissonance creates a sense of eeriness in
							the observer, dropping the digital twin into the uncanny valley
							(Prof. Masahiro Mori, 1970). The twin is not perceived as an
							authentic and genuine manifestation of the actual person.
						</p>

						<p>
							<em>Abstract You</em> doubts the assumption that a hyper-realistic
							portrayal is necessarily the most authentic digital representation
							of a person. The project suggests that a basic and abstract visual
							manifestation might offer more potential for authenticity. Can we
							sample and distill a person's attributes into an abstract line,
							instead of a realistic digital figure? Would this person’s traits
							still be identifiable in this line?
						</p>

						<p>
							In the project, an abstract linear form is created through an
							interactive interface which samples three unique human attributes:
							body movements, facial emotion recognition and voice. These
							attributes are recorded, analysed in real-time using machine
							learning, and are then converted into an animated linear shape, a
							unique line for each person.
						</p>

					</section>

					<hr />
					<section>
						<dl>
							<dt>
 Research, Concept and Design: 
							</dt>
							<dd>
Ben Lev
							</dd>
							<dt>Development:</dt>
							<dd>Ran Hartstein</dd>
						</dl>
					</section>

					<section>
						<p><em>Abstract You</em> uses code from the following projects:</p>
						<p>
							<a href="https://p5js.org/">P5.js</a>, Lauren McCarthy, LGPL 2.1
						</p>
						<p><a href="https://ml5js.org/">ml5.js</a>, MIT</p>
						<p>
							<a href="https://github.com/mveteanu/p5.SceneManager">p5.js SceneManager</a>, Marian Veteneau, CC BY 2.0
						</p>
						<p>
							<a href="https://github.com/AndriiHeonia/hull">Hull.js</a>, Andrii
							Heonia, BSD 3
						</p>
					</section>
				</div>
				<div class="sidebar">
					<figure>
						<img src="" alt="Image">
						<figcaption>Image</figcaption>
					</figure>
					<figure>
						<img src="" alt="Image">
						<figcaption>Image</figcaption>
					</figure>
				</div>
			</article>
		</div>
	</main>
	<div id="dat-gui-container"></div>
</body>

</html>